{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CHAPTER 1. Pangenome analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the modules needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from Bio import Entrez, SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this study `PanACoTA` software will be used for Pangenome analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PanACoTA` uses `Prokka` for homologous genomes annotations, which is not good for fungal genomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we will use already annotated mitochondrial genomes from `RefSeq` database!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a directory to store all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir pangenome/\n",
    "mkdir pangenome/data/\n",
    "mkdir pangenome/Annotation/\n",
    "mkdir pangenome/Annotation/Genes/\n",
    "mkdir pangenome/Annotation/Proteins/\n",
    "mkdir pangenome/Annotation/Proteins_classic/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will need the list of accession numbers of fungal complete mitochondrial genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! esearch -db nucleotide \\\n",
    "    -query '(\"Leotiomycetes\"[Organism] OR Leotiomycetes[All Fields]) AND srcdb_refseq[PROP] AND (fungi[filter] AND mitochondrion[filter])' \\\n",
    "    | efetch -format acc > pangenome/data/accession_numbers.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will download us everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences(email, file_path, output_dir, format, extension):\n",
    "    Entrez.email = email\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Read accession numbers from file\n",
    "    with open(file_path, \"r\") as file:\n",
    "        accession_numbers = file.read().split()\n",
    "\n",
    "    def download_sequence(accession):\n",
    "        \"\"\"Fetches a single sequence from NCBI and saves it as a FASTA file.\"\"\"\n",
    "        try:\n",
    "            handle = Entrez.efetch(\n",
    "                db=\"nucleotide\", id=accession, rettype=format, retmode=\"text\"\n",
    "            )\n",
    "            records = list(SeqIO.parse(handle, \"fasta\"))  # Use parse() instead of read()\n",
    "            handle.close()\n",
    "\n",
    "            if records:\n",
    "                output_path = os.path.join(output_dir, f\"{accession.split('.')[0]}.{extension}\")\n",
    "                SeqIO.write(records, output_path, \"fasta\")\n",
    "                print(f\"Downloaded: {accession}\")\n",
    "            else:\n",
    "                print(f\"No CDS found for {accession}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {accession}: {e}\")\n",
    "\n",
    "    # Download sequences for each accession number\n",
    "    for accession in accession_numbers:\n",
    "        download_sequence(accession)\n",
    "\n",
    "    print(\"All downloads completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"sample@email.com\" #ENTER YOUR EMAIL\n",
    "accession_numbers = \"pangenome/data/accession_numbers.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sequences(email,\n",
    "              accession_numbers,\n",
    "              \"pangenome/Annotation/Genes\",\n",
    "              format = \"fasta_cds_na\",\n",
    "              extension = \"gen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download proteomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sequences(email,\n",
    "              accession_numbers,\n",
    "              \"pangenome/Annotation/Proteins_classic\",\n",
    "              format = \"fasta_cds_aa\",\n",
    "              extension = \"prt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to rename downloaded mitochondrial proteomes to make them face the requirements of `PanACoTA` input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for file in pangenome/Annotation/Proteins_classic/*.prt; do \n",
    "    awk '{\n",
    "        if ($0 ~ /^>/) {\n",
    "            gsub(/^>lcl\\|/,\">\");                        # Remove \"lcl|\"\n",
    "            match($0, /^>([^.]+)\\.[0-9]+_prot_/, g);    # Extract genome name (e.g., NC_015789)\n",
    "            match($0, /_prot_YP_([0-9]+)/, id);         # Extract numeric protein ID (e.g., 004733034)\n",
    "            if (g[1] != \"\" && id[1] != \"\") {\n",
    "                print \">\" g[1] \"_\" id[1];               # Format as genomeName_numericID\n",
    "            } else {\n",
    "                print \">\" $2;  # Fallback if parsing fails\n",
    "            }\n",
    "        } else {\n",
    "            print;\n",
    "        }\n",
    "    }' \"$file\" > pangenome/Annotation/Proteins/$(basename \"$file\")\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the renaming from proteomes to genomes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "proteins_dir = \"pangenome/Annotation/Proteins\"\n",
    "genes_dir = \"pangenome/Annotation/Genes\"\n",
    "\n",
    "# Ensure Genes directory exists\n",
    "if not os.path.exists(genes_dir):\n",
    "    print(\"Genes directory does not exist.\")\n",
    "    exit(1)\n",
    "\n",
    "# Function to extract FASTA sequences\n",
    "def read_fasta(file_path):\n",
    "    sequences = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        seq = []\n",
    "        header = None\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if header:\n",
    "                    sequences.append((header, \"\\n\".join(seq)))\n",
    "                header = line  # Store new header\n",
    "                seq = []\n",
    "            else:\n",
    "                seq.append(line)\n",
    "        if header:\n",
    "            sequences.append((header, \"\\n\".join(seq)))  # Append last sequence\n",
    "    return sequences\n",
    "\n",
    "# Function to write updated FASTA sequences\n",
    "def write_fasta(file_path, sequences):\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for header, seq in sequences:\n",
    "            f.write(f\"{header}\\n{seq}\\n\")\n",
    "\n",
    "# Process all .prt files in Proteins directory\n",
    "for prt_file in os.listdir(proteins_dir):\n",
    "    if prt_file.endswith(\".prt\"):\n",
    "        # Get corresponding .gen file\n",
    "        base_name = os.path.splitext(prt_file)[0]  # Remove .prt extension\n",
    "        gen_file = f\"{base_name}.gen\"\n",
    "        \n",
    "        prt_path = os.path.join(proteins_dir, prt_file)\n",
    "        gen_path = os.path.join(genes_dir, gen_file)\n",
    "\n",
    "        # Check if corresponding .gen file exists\n",
    "        if not os.path.exists(gen_path):\n",
    "            print(f\"Skipping {gen_file} (not found in Genes directory)\")\n",
    "            continue\n",
    "\n",
    "        # Read sequences from .prt and .gen files\n",
    "        prt_seqs = read_fasta(prt_path)\n",
    "        gen_seqs = read_fasta(gen_path)\n",
    "\n",
    "        # Ensure both files have the same number of sequences\n",
    "        if len(prt_seqs) != len(gen_seqs):\n",
    "            print(f\"Skipping {gen_file} (mismatch: {len(prt_seqs)} protein seqs vs {len(gen_seqs)} gene seqs)\")\n",
    "            continue\n",
    "\n",
    "        # Replace headers in .gen file\n",
    "        updated_gen_seqs = [(prt_seqs[i][0], gen_seqs[i][1]) for i in range(len(gen_seqs))]\n",
    "\n",
    "        # Write updated .gen file\n",
    "        write_fasta(gen_path, updated_gen_seqs)\n",
    "        print(f\"Updated {gen_file} with new headers from {prt_file}\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a list file with the proteomes to build the pangenome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls pangenome/Annotation/Proteins/*.prt | sed 's|pangenome/Annotation/Proteins/||' | sed 's/\\.prt$//' >\\\n",
    "    pangenome/Annotation/LSTINFO-.lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we must create a merged proteomes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat pangenome/Annotation/Proteins/* > pangenome/Annotation/Proteins/LeMy.All.prt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Now let's construct a pangenome with the proteins identity setting = `0.9` (90%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m  * [2025-03-17 21:18:57] : INFO \u001b[0m PanACoTA version 1.4.0\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:18:57] : INFO \u001b[0m Command used\n",
      " \t > PanACoTA pangenome -l pangenome/Annotation/LSTINFO-.lst -n LeMy -d pangenome/Annotation/Proteins/ -o pangenome/Pangenome -i 0.9\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:18:57] : INFO \u001b[0m Will run MMseqs2 with:\n",
      "\t- minimum sequence identity = 90.0%\n",
      "\t- cluster mode 1\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:18:57] : INFO \u001b[0m Reading and getting information from pangenome file\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:18:57] : INFO \u001b[0m Retrieving information from pan families\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:18:57] : INFO \u001b[0m Generating qualitative and quantitative matrix, and summary file\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:18:57] : INFO \u001b[0m DONE\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! PanACoTA pangenome -l pangenome/Annotation/LSTINFO-.lst -n LeMy -d pangenome/Annotation/Proteins/ -o pangenome/Pangenome -i 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now please proceed to the `02_pangenome_visualization.R` and run the analysis there. Then come back!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are 4 genes that are presented in more than 17 genomes out of 24! 17 is more than 16, so let's calculate the percentage of genomes sharing these 4 genes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.66666666666667"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16 * 100 / 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now run `PanACoTA`'s `corepers` module to extract those genes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m  * [2025-03-17 21:19:07] : INFO \u001b[0m PanACoTA version 1.4.0\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:19:07] : INFO \u001b[0m Command used\n",
      " \t > PanACoTA corepers -p pangenome/Pangenome/PanGenome-LeMy.All.prt-clust-0.9-mode1.lst -o pangenome/Coregenome -t 0.66\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:19:07] : INFO \u001b[0m Will generate a Persistent genome with member(s) in at least 66.0% of all genomes in each family.\n",
      "To be considered as persistent, a family must contain exactly 1 member in at least 66.0% of all genomes. The other genomes are absent from the family.\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:19:07] : INFO \u001b[0m Retrieving info from binary file\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:19:07] : INFO \u001b[0m Generating Persistent genome of a dataset containing 24 genomes\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:19:07] : INFO \u001b[0m The persistent genome contains 4 families, each one having exactly 1 member from at least 66.0% of the 24 different genomes (that is 16 genomes). The other genomes are absent from the family.\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:19:07] : INFO \u001b[0m Persistent genome step done.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! PanACoTA corepers -p pangenome/Pangenome/PanGenome-LeMy.All.prt-clust-0.9-mode1.lst -o pangenome/Coregenome -t 0.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process `pangenome/Annotation/LSTINFO-.lst` file to leave there only those 66% of genomes that have 4 commonly shared genes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(input_txt, input_tsv, output_tsv):\n",
    "    \"\"\"\n",
    "    Processes two input files and creates a filtered TSV file.\n",
    "\n",
    "    Args:\n",
    "        input_txt (str): Path to the input TXT file.\n",
    "        input_tsv (str): Path to the input TSV file (no header, one column).\n",
    "        output_tsv (str): Path to the output TSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    def trim_identifier(identifier):\n",
    "        \"\"\"\n",
    "        Trims the identifier to retain only the part before the 2nd underscore.\n",
    "\n",
    "        Args:\n",
    "            identifier (str): The full identifier string.\n",
    "\n",
    "        Returns:\n",
    "            str: The trimmed identifier.\n",
    "        \"\"\"\n",
    "        return \"_\".join(identifier.split(\"_\")[:2])\n",
    "\n",
    "    # Extract trimmed \"gembase_name\" values from the first two rows of the TXT file\n",
    "    with open(input_txt, \"r\") as txt_file:\n",
    "        lines = txt_file.readlines()\n",
    "        if len(lines) < 2:\n",
    "            raise ValueError(\"The TXT file must have at least two rows.\")\n",
    "        first_row = lines[0].strip().split()\n",
    "        second_row = lines[1].strip().split()\n",
    "        gembase_names = {trim_identifier(item) for item in first_row + second_row}\n",
    "\n",
    "    # Read the TSV file (single column, no header) and filter rows\n",
    "    with open(input_tsv, \"r\") as tsv_file:\n",
    "        reader = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "        filtered_rows = [\n",
    "            row for row in reader if trim_identifier(row[0]) in gembase_names\n",
    "        ]\n",
    "\n",
    "    # Write the filtered rows to a new TSV file (single column, no header)\n",
    "    with open(output_tsv, \"w\", newline=\"\") as out_file:\n",
    "        writer = csv.writer(out_file, delimiter=\"\\t\")\n",
    "        writer.writerows(filtered_rows)\n",
    "\n",
    "    print(f\"Filtered file created: {output_tsv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered file created: pangenome/Annotation/fLSTINFO-.lst\n"
     ]
    }
   ],
   "source": [
    "input_txt = \"pangenome/Coregenome/PersGenome_PanGenome-LeMy.All.prt-clust-0.9-mode1.lst-all_0.66.lst\"\n",
    "input_tsv = \"pangenome/Annotation/LSTINFO-.lst\"\n",
    "output_tsv = \"pangenome/Annotation/fLSTINFO-.lst\"\n",
    "\n",
    "process_files(input_txt, input_tsv, output_tsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lifehack: instead of running `MAFFT` by ourselves, we can still run `PanACoTA`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m  * [2025-03-17 21:19:11] : INFO \u001b[0m PanACoTA version 1.4.0\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:19:11] : INFO \u001b[0m Command used\n",
      " \t > PanACoTA align -c pangenome/Coregenome/PersGenome_PanGenome-LeMy.All.prt-clust-0.9-mode1.lst-all_0.66.lst -l pangenome/Annotation/fLSTINFO-.lst -n LeMy -d pangenome/Annotation/ -o pangenome/Alignment\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:19:11] : INFO \u001b[0m Found 23 genomes.\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:19:11] : INFO \u001b[0m Reading PersGenome and constructing lists of missing genomes in each family.\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:19:11] : INFO \u001b[0m Getting all persistent proteins and classify by strain.\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:19:11] : INFO \u001b[0m All extraction files already existing (see detailed log for more information)\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:19:11] : INFO \u001b[0m Starting alignment of all families: protein alignment, back-translation to nucleotides, and add missing genomes in the family\u001b[0m\n",
      "Alignment:                                0/4 (  0%) - Elapsed Time: 0:00:00 - \u001b[32m  * [2025-03-17 21:19:11] : INFO \u001b[0m nucl alignments already concatenated\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:19:11] : INFO \u001b[0m nucleic alignments already grouped by genome\u001b[0m\n",
      "\u001b[32m  * [2025-03-17 21:19:11] : INFO \u001b[0m END\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! PanACoTA align -c pangenome/Coregenome/PersGenome_PanGenome-LeMy.All.prt-clust-0.9-mode1.lst-all_0.66.lst\\\n",
    "    -l pangenome/Annotation/fLSTINFO-.lst -n LeMy -d pangenome/Annotation/ -o pangenome/Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to work with MSAs a little bit<br>\n",
    "First, create a directory where to store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir pangenome/Alignment/MSAs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the current state of MSAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">NC_015789_004733052\n"
     ]
    }
   ],
   "source": [
    "! head -1 pangenome/Alignment/Align-LeMy/LeMy-mafft-align.6.aln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's good. We just need to delete everything after the 2nd `_` including that 2nd `_`. Also, it will be good to rename files to know what gene is in that MSA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_msa(input_fasta, output_fasta):\n",
    "    \"\"\"\n",
    "    Processes a multiple sequence alignment (MSA) file, renaming sequence headers\n",
    "    by removing everything after the first underscore in each header.\n",
    "\n",
    "    Args:\n",
    "        input_fasta (str): Path to the input FASTA file.\n",
    "        output_fasta (str): Path to save the processed FASTA file.\n",
    "    \"\"\"\n",
    "\n",
    "    def trim_header(header):\n",
    "        \"\"\"Removes everything after the 2nd underscore in a sequence header.\"\"\"\n",
    "        return \"_\".join(header.split(\"_\")[:2])\n",
    "\n",
    "    # Read and process the FASTA file\n",
    "    with open(input_fasta, \"r\") as infile, open(output_fasta, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            if line.startswith(\">\"):  # Header line\n",
    "                new_header = f\">{trim_header(line[1:].strip())}\\n\"\n",
    "                outfile.write(new_header)\n",
    "            else:\n",
    "                outfile.write(line)  # Write sequence lines unchanged\n",
    "\n",
    "    print(f\"Processed MSA saved to {output_fasta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">NC_015789_004733052\n",
      ">lcl|NC_015789.1_prot_YP_004733052.1_19 [gene=ND4L] [locus_tag=PhsufM_p19] [db_xref=GeneID:10963959] [protein=NADH dehydrogenase subunit 4L] [protein_id=YP_004733052.1] [location=37495..37764] [gbkey=CDS]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "head -1 pangenome/Alignment/Align-LeMy/LeMy-mafft-align.6.aln\n",
    "id=$(head -1 pangenome/Alignment/Align-LeMy/LeMy-mafft-align.6.aln | cut -d'_' -f3)\n",
    "grep \"$id\" pangenome/Annotation/Proteins_classic/NC_015789.prt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed MSA saved to pangenome/Alignment/MSAs/nad4l.aln\n"
     ]
    }
   ],
   "source": [
    "fasta_file = 'pangenome/Alignment/Align-LeMy/LeMy-mafft-align.6.aln'\n",
    "output_fasta_file = 'pangenome/Alignment/MSAs/nad4l.aln'\n",
    "\n",
    "process_msa(fasta_file, output_fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">NC_015789_004733049\n",
      ">lcl|NC_015789.1_prot_YP_004733049.1_16 [gene=COX2] [locus_tag=PhsufM_p16] [db_xref=GeneID:10963961] [protein=cytochrome c oxidase subunit II] [protein_id=YP_004733049.1] [location=31173..31922] [gbkey=CDS]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "head -1 pangenome/Alignment/Align-LeMy/LeMy-mafft-align.32.aln\n",
    "id=$(head -1 pangenome/Alignment/Align-LeMy/LeMy-mafft-align.32.aln | cut -d'_' -f3)\n",
    "grep \"$id\" pangenome/Annotation/Proteins_classic/NC_015789.prt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed MSA saved to pangenome/Alignment/MSAs/cox2.aln\n"
     ]
    }
   ],
   "source": [
    "fasta_file = 'pangenome/Alignment/Align-LeMy/LeMy-mafft-align.32.aln'\n",
    "output_fasta_file = 'pangenome/Alignment/MSAs/cox2.aln'\n",
    "\n",
    "process_msa(fasta_file, output_fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">NC_015789_004733054\n",
      ">lcl|NC_015789.1_prot_YP_004733054.1_21 [gene=CYTB] [locus_tag=PhsufM_p21] [db_xref=GeneID:10963966] [protein=cytochrome b] [protein_id=YP_004733054.1] [location=41872..43038] [gbkey=CDS]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "head -1 pangenome/Alignment/Align-LeMy/LeMy-mafft-align.130.aln\n",
    "id=$(head -1 pangenome/Alignment/Align-LeMy/LeMy-mafft-align.130.aln | cut -d'_' -f3)\n",
    "grep \"$id\" pangenome/Annotation/Proteins_classic/NC_015789.prt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed MSA saved to pangenome/Alignment/MSAs/cob.aln\n"
     ]
    }
   ],
   "source": [
    "fasta_file = 'pangenome/Alignment/Align-LeMy/LeMy-mafft-align.130.aln'\n",
    "output_fasta_file = 'pangenome/Alignment/MSAs/cob.aln'\n",
    "\n",
    "process_msa(fasta_file, output_fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">NC_015789_004733034\n",
      ">lcl|NC_015789.1_prot_YP_004733034.1_1 [gene=COX1] [locus_tag=PhsufM_p01] [db_xref=GeneID:10963948] [protein=cytochrome c oxidase subunit I] [protein_id=YP_004733034.1] [location=481..2202] [gbkey=CDS]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "head -1 pangenome/Alignment/Align-LeMy/LeMy-mafft-align.565.aln\n",
    "id=$(head -1 pangenome/Alignment/Align-LeMy/LeMy-mafft-align.565.aln | cut -d'_' -f3)\n",
    "grep \"$id\" pangenome/Annotation/Proteins_classic/NC_015789.prt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed MSA saved to pangenome/Alignment/MSAs/cox1.aln\n"
     ]
    }
   ],
   "source": [
    "fasta_file = 'pangenome/Alignment/Align-LeMy/LeMy-mafft-align.565.aln'\n",
    "output_fasta_file = 'pangenome/Alignment/MSAs/cox1.aln'\n",
    "\n",
    "process_msa(fasta_file, output_fasta_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the MSAs are ready it is time to trim them all!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a directory to store trimmed MSAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir pangenome/Alignment/trimmed_MSAs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run a bash loop with `trimAl` in it on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for msa in pangenome/Alignment/MSAs/*.aln\n",
    "do trimal -in $msa -out pangenome/Alignment/trimmed_MSAs/$(basename \"$msa\" .aln)_trim.fa -automated1\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got the trimmed MSAs! Now what? `MODELFINDER`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a directory to store `ModelFinder` log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir pangenome/model-finder/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run a bash loop with `ModelFinder` in it on trimmed MSAs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for msa in pangenome/Alignment/trimmed_MSAs/*_trim.fa\n",
    "do \n",
    "    iqtree2 -m MFP -s $msa --prefix pangenome/model-finder/$(basename \"$msa\" _trim.fa) -T AUTO\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best fit model for `nad4l`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-fit model according to BIC: mtZOA\n",
      "\n",
      "List of models sorted by BIC scores: \n",
      "\n",
      "Model                  LogL         AIC      w-AIC        AICc     w-AICc         BIC      w-BIC\n",
      "mtZOA              -271.267     592.535 +    0.136     618.025 +    0.777     651.130 +    0.755\n"
     ]
    }
   ],
   "source": [
    "! head -42 pangenome/model-finder/nad4l.iqtree | tail -6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best fit model for `cox2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-fit model according to BIC: Q.plant+G4\n",
      "\n",
      "List of models sorted by BIC scores: \n",
      "\n",
      "Model                  LogL         AIC      w-AIC        AICc     w-AICc         BIC      w-BIC\n",
      "Q.plant+G4         -967.262    2002.524 +    0.346    2015.389 +    0.383    2117.908 +    0.446\n"
     ]
    }
   ],
   "source": [
    "! head -42 pangenome/model-finder/cox2.iqtree | tail -6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best fit model for `cob`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-fit model according to BIC: mtZOA+G4\n",
      "\n",
      "List of models sorted by BIC scores: \n",
      "\n",
      "Model                  LogL         AIC      w-AIC        AICc     w-AICc         BIC      w-BIC\n",
      "mtZOA+G4          -1726.355    3512.710 +    0.339    3518.398 +    0.383    3629.126 +    0.732\n"
     ]
    }
   ],
   "source": [
    "! head -42 pangenome/model-finder/cob.iqtree | tail -6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best fit model for `cox1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-fit model according to BIC: mtZOA+R2\n",
      "\n",
      "List of models sorted by BIC scores: \n",
      "\n",
      "Model                  LogL         AIC      w-AIC        AICc     w-AICc         BIC      w-BIC\n",
      "mtZOA+R2          -2329.417    4720.834 +    0.593    4724.770 +    0.731    4853.642 +    0.483\n"
     ]
    }
   ],
   "source": [
    "! head -42 pangenome/model-finder/cox1.iqtree | tail -6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last... We have best fit models for all of our 4 genes... It's time to launch `IQ-TREE`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a directory to store the trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir pangenome/tree/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run a bash loop with `IQ-TREE` in it on trimmed MSAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for msa in pangenome/Alignment/trimmed_MSAs/*_trim.fa\n",
    "do \n",
    "    if [[ \"$msa\" == \"nad4l.fa\" ]]; then\n",
    "        model=\"mtZOA\"\n",
    "    elif [[ \"$msa\" == \"cox2.fa\" ]]; then\n",
    "        model=\"Q.plant+G4\"\n",
    "    elif [[ \"$msa\" == \"cob.fa\" ]]; then\n",
    "        model=\"mtZOA+G4\"\n",
    "    elif [[ \"$msa\" == \"cox1.fa\" ]]; then\n",
    "        model=\"mtZOA+R2\"\n",
    "    fi\n",
    "\n",
    "    iqtree2 -s \"$msa\" -m \"$model\" -pre pangenome/tree/$(basename \"$msa\" _trim.fa)_ufb -bb 10000 -nt AUTO\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is adding `.1` to accession numbers on the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_tree_file(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Reads a Newick tree from a file, adds \".1\" to all accession numbers, \n",
    "    and writes the modified tree to an output file.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to the input tree file.\n",
    "        output_file (str): Path to save the modified tree.\n",
    "    \"\"\"\n",
    "\n",
    "    def add_suffix(match):\n",
    "        return match.group(0) + \".1\"\n",
    "\n",
    "    # Read tree from file\n",
    "    with open(input_file, \"r\") as infile:\n",
    "        tree_str = infile.read().strip()\n",
    "\n",
    "    # Modify tree\n",
    "    modified_tree = re.sub(r'NC_\\d+', add_suffix, tree_str)\n",
    "\n",
    "    # Write modified tree to output file\n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        outfile.write(modified_tree)\n",
    "\n",
    "    print(f\"Modified tree saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified tree saved to: pangenome/tree/nad4l_ufb_ready.treefile\n",
      "Modified tree saved to: pangenome/tree/cox2_ufb_ready.treefile\n",
      "Modified tree saved to: pangenome/tree/cob_ufb_ready.treefile\n",
      "Modified tree saved to: pangenome/tree/cox1_ufb_ready.treefile\n"
     ]
    }
   ],
   "source": [
    "tree_files = [\"nad4l\", \"cox2\", \"cob\", \"cox1\"]\n",
    "\n",
    "for gene in tree_files:\n",
    "    input_tree_file = f\"pangenome/tree/{gene}_ufb.treefile\"\n",
    "    output_tree_file = f\"pangenome/tree/{gene}_ufb_ready.treefile\"\n",
    "    modify_tree_file(input_tree_file, output_tree_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually that's all!<br>\n",
    "But now we'll fetch metadata on _Leotiomycetes_ fungi from NCBI RefSeq<br>\n",
    "It will be used to annotate the trees in `ggtree`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a directory where to store metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fetch metadata!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir metadata/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! Phyloki --fetch_metadata -email sample@email.com -i pangenome/data/accession_numbers.txt -o metadata/raw_metadata.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will clean the `Year` column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_year(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Clean the 'Year' column in a metadata .tsv file to extract only the last 4 digits.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to the input .tsv file.\n",
    "        output_file (str): Path to save the cleaned .tsv file.\n",
    "    \"\"\"\n",
    "    # Load the .tsv file into a DataFrame\n",
    "    df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "    # Extract the last 4 digits of the 'Year' column\n",
    "    df['Year'] = df['Year'].apply(lambda x: str(x)[-4:] if pd.notnull(x) else 'ND')\n",
    "\n",
    "    # Save the updated DataFrame to a new .tsv file\n",
    "    df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "    print(f\"The 'Year' column has been cleaned.\\nFile saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_year('metadata/raw_metadata.tsv',\n",
    "           'metadata/metadata.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for pangenome analysis! Please proceed to the `03_phylogenomics.ipynb` for further analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panphylo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
